"use strict";Object.defineProperty(exports,"__esModule",{value:!0});var MetricReduction,globals_1=require("../globals"),tensor_1=require("../tensor"),session_1=require("./session"),DEFAULT_EVAL_INTERVAL_MS=1500,DEFAULT_COST_INTERVAL_MS=500,DEFAULT_INFERENCE_EXAMPLE_INTERVAL_MS=3e3;!function(e){e[e.SUM=0]="SUM",e[e.MEAN=1]="MEAN"}(MetricReduction=exports.MetricReduction||(exports.MetricReduction={}));var GraphRunner=function(){function e(e,t,r){this.math=e,this.session=t,this.eventObserver=r,this.lastCostTimestamp=0,this.lastEvalTimestamp=0,this.resetStatistics(),this.zeroScalar=tensor_1.Scalar.new(0)}return e.prototype.resetStatistics=function(){this.totalBatchesTrained=0},e.prototype.train=function(e,t,r,n,i,s,a,o,c,l,h){void 0===c&&(c=MetricReduction.MEAN),void 0===l&&(l=DEFAULT_EVAL_INTERVAL_MS),void 0===h&&(h=DEFAULT_COST_INTERVAL_MS),this.costTensor=e,this.trainFeedEntries=t,this.metricTensor=s,this.metricFeedEntries=a,null!=o&&this.metricBatchSize!==o&&(null!=this.metricBatchSizeScalar&&this.metricBatchSizeScalar.dispose(),this.metricBatchSizeScalar=tensor_1.Scalar.new(o)),this.metricBatchSize=o,this.metricReduction=c,this.batchSize=r,this.optimizer=n,this.metricIntervalMs=l,this.costIntervalMs=h,this.currentTrainLoopNumBatches=i,this.batchesTrainedThisRun=0,this.isTraining=!0,this.trainStartTimestamp=performance.now(),this.trainNetwork()},e.prototype.stopTraining=function(){this.isTraining=!1},e.prototype.resumeTraining=function(){this.isTraining=!0,this.trainNetwork()},e.prototype.trainNetwork=function(){var n,i,s,a=this;this.batchesTrainedThisRun===this.currentTrainLoopNumBatches&&this.stopTraining(),this.isTraining?(n=performance.now(),(i=null!=this.eventObserver.avgCostCallback&&n-this.lastCostTimestamp>this.costIntervalMs)&&(this.lastCostTimestamp=n),s=i?session_1.CostReduction.MEAN:session_1.CostReduction.NONE,globals_1.tidy(function(){var e,t,r=a.session.train(a.costTensor,a.trainFeedEntries,a.batchSize,a.optimizer,s);i&&(e=performance.now()-n,a.eventObserver.avgCostCallback(r),null!=a.eventObserver.trainExamplesPerSecCallback&&(t=1e3*a.batchSize/e,a.eventObserver.trainExamplesPerSecCallback(t))),null!=a.eventObserver.metricCallback&&null!=a.metricFeedEntries&&n-a.lastEvalTimestamp>a.metricIntervalMs&&(a.lastEvalTimestamp=n,null!=a.lastComputedMetric&&a.lastComputedMetric.dispose(),a.lastComputedMetric=a.computeMetric(),a.eventObserver.metricCallback(a.lastComputedMetric)),null!=a.eventObserver.totalTimeCallback&&a.eventObserver.totalTimeCallback((n-a.trainStartTimestamp)/1e3),a.batchesTrainedThisRun++,a.totalBatchesTrained++,null!=a.eventObserver.batchesTrainedCallback&&a.eventObserver.batchesTrainedCallback(a.totalBatchesTrained)}),requestAnimationFrame(function(){return a.trainNetwork()})):null!=this.eventObserver.doneTrainingCallback&&this.eventObserver.doneTrainingCallback()},e.prototype.infer=function(e,t,r,n,i){var s=this;if(void 0===r&&(r=DEFAULT_INFERENCE_EXAMPLE_INTERVAL_MS),void 0===n&&(n=5),null==this.eventObserver.inferenceExamplesCallback&&null==this.eventObserver.inferenceExamplesPerSecCallback)throw new Error("Cannot start inference loop, no inference example or examples/sec observer provided.");for(var a=0;a<t.length;a++){if(t[a].data instanceof tensor_1.Tensor)throw new Error("Cannot start inference on the model runner with feed entries of type NDArray. Please use InputProviders.")}this.inferenceExampleIntervalMs=r,this.inferenceTensor=e,this.inferenceFeedEntries=t,this.inferenceExampleCount=n,this.currentInferenceLoopNumPasses=i,this.isInferring||(this.inferencePassesThisRun=0,requestAnimationFrame(function(){return s.inferNetwork()})),this.isInferring=!0},e.prototype.inferNetwork=function(){var h=this;this.isInferring&&this.inferencePassesThisRun!==this.currentInferenceLoopNumPasses&&(globals_1.tidy(function(){for(var e,t,r=[],n=[],i=performance.now(),s=0;s<h.inferenceExampleCount;s++){for(var a=[],o=0;o<h.inferenceFeedEntries.length;o++){var c=h.inferenceFeedEntries[o],l=c.data.getNextCopy();a.push({tensor:c.tensor,data:l})}r.push(a),n.push(h.session.eval(h.inferenceTensor,a))}null!=h.eventObserver.inferenceExamplesPerSecCallback&&(n[n.length-1].dataSync(),e=performance.now()-i,t=1e3*h.inferenceExampleCount/e,h.eventObserver.inferenceExamplesPerSecCallback(t)),null!=h.eventObserver.inferenceExamplesCallback&&h.eventObserver.inferenceExamplesCallback(r,n),h.inferencePassesThisRun++}),this.lastInferTimeoutID=window.setTimeout(function(){return h.inferNetwork()},this.inferenceExampleIntervalMs))},e.prototype.stopInferring=function(){this.isInferring=!1,window.clearTimeout(this.lastInferTimeoutID)},e.prototype.isInferenceRunning=function(){return this.isInferring},e.prototype.computeMetric=function(){var r=this;if(null==this.metricFeedEntries)throw new Error("Cannot compute metric, no metric FeedEntries provided.");var n=this.zeroScalar;return globals_1.tidy(function(){for(var e=0;e<r.metricBatchSize;e++){var t=r.session.eval(r.metricTensor,r.metricFeedEntries);n=r.math.add(n,t.toFloat())}return r.metricReduction===MetricReduction.MEAN&&(n=r.math.divide(n,r.metricBatchSizeScalar)),n})},e.prototype.getTotalBatchesTrained=function(){return this.totalBatchesTrained},e.prototype.getLastComputedMetric=function(){return this.lastComputedMetric},e.prototype.setMath=function(e){this.math=e},e.prototype.setSession=function(e){this.session=e},e.prototype.setInferenceTensor=function(e){this.inferenceTensor=e},e.prototype.setInferenceExampleCount=function(e){this.inferenceExampleCount=e},e}();exports.GraphRunner=GraphRunner;